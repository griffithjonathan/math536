---
title: "Lecture03OLS.Rmd"
author: "Doug Nychka"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Learning Objectives

- Being able to interpret a linear model and the parameter estimates based on matrix expressions. 

- Evaluate a general form for the statistical linear model.

- Understand how categorical variables  are encoded in a linear model

- Checking a linear model and the results of  transforming using the log function. 

- Adding and interpreting an interaction

- Weighted least squares 

\newpage

```{r }
setwd("~/Dropbox/Home/Teaching/AMS536/theCourse/ClassLectures/Lecture03")
library( GLMsData)
data( lungcap)
suppressMessages(library( fields))
```

## Sensible factor levels for smoking
```{r}
table(lungcap$Smoke)
lungcap$Smoke <-factor( lungcap$Smoke, 
                        levels=c(0,1),
                        labels=c("NS", "S" )
                        )
                        
head( lungcap)
```

# OLS on raw  response
Using the formula language in R. 

```{r}
lmObj<- lm( FEV ~ Age + Ht + Smoke + Gender, data= lungcap )
```

\newpage
```{r}
summary( lmObj)

``` 

# Direct computation of lm results 
Now reproduce these by hand to show how the categorical variables,
Gender and Smoker actually enter the model 

```{r}
# y = XBeta + epsilon
y<- lungcap$FEV

# First col is 1's for constant term
# Recode the numerics to 0 and 1 instead of 1 and 2
X<- cbind(1, lungcap$Age, lungcap$Ht,
          as.numeric( lungcap$Smoke) - 1,
          as.numeric( lungcap$Gender) -1)
head( X,3)
tail(X,3)

# Very small proportion of smokers
table( X[,4], X[,5])

```



# The OLS estimates 
```{r}

#OLS formula is
# Betahat = (xtx)^-1 xty
# xtx = 5x5
# xty = 5x1
# solve() inverts a matrix while t() transpose matrix
betaHat<-  ( solve( t(X)%*%X) ) %*% t(X)%*%y

c(betaHat)

lmObj$coefficients

```
Agreement with ``` lm ``` results!

\newpage

# Finding standard errors.

Now find the estimate of  $\sigma$, the error  SD. 
```{r}
yHat<- X%*%betaHat    #predicted values from the model
residuals<- y - yHat     # difference between predicted and observed
n<- nrow( X)             # num of observations
p<- ncol( X)             # num of params
sigmaHat<- sqrt( sum( residuals^2)/ ( n-p) )
summary( lmObj)$sigma 
```

Reproduce the standard error computation.
```{r}

covBeta<- sigmaHat^2 * solve (t(X)%*%X)
SE<- sqrt( diag( covBeta) )

cbind( betaHat, SE)
# compare to 
summary(lmObj)$coefficients[,1:2]

## interpret as conf interval calc
## SmokeS conf interval is approx -0.087 +- (1.96)(0.05925)
## Take into account low p value
```
```{r}
confint(lmObj)
```


\newpage

# Model checking

Now finally check this model. 
```{r}
plot( yHat, residuals)
``` 
Clearly dependence of residuals on size of predicted value. Try a log transform to fix this. 

```{r}
lmObj2<- lm( log10(FEV) ~ 
               Age + Ht + Smoke + Gender, data= lungcap )
```

```{r}
summary( lmObj2)
```

The new residual plot. 
```{r}
plot( lmObj2$fitted.values, lmObj2$residuals)
``` 

Much better!

\newpage

## Including an interaction 
```{r}
# Make four different groups for smokers and gender
# THink of interaction variables as the effect of smoking and alcohol separately vs together. Sleepy separately, deadly together
lmObj3<- lm( log10(FEV) ~ Age + Ht + Smoke*Gender, data= lungcap )
summary( lmObj3)$coefficients
```

Main effect and  the interaction for 2 levels has a
simple
interpretation based how covariates are coded as (0,1).


\newpage

Confirm interaction not important based on residuals from the 
main effects model.


```{r}
interaction<- X[,4]* X[,5]
colInteraction<- ifelse( interaction==0,  "grey90","green")
plot(lmObj2$fitted.values, lmObj2$residuals, 
     col= colInteraction, pch=16, cex=1)
points( lmObj2$fitted.values, lmObj2$residuals, col="black",
        cex=1)
```


## ANOVA 

ANOVA is a basic strategy to compare nested models. 
In this case the model just using Gender and Smoker and then the 
model adding in the covariates. 
Here is a fit to the reduced model.
```{r}
lmObj3B<- lm( log10(FEV) ~  Smoke*Gender, data= lungcap )
summary( lmObj3B)
```

Sums of squares of the reduced model and the full one
and the mean squares

```{r}
SS3B<- sum( lmObj3B$residuals^2)

SS3<- sum( lmObj3$residuals^2)

MSE <- (SS3B - SS3) / ( 2)
MSER <- (SS3)/ ( n - 6)

F<- MSE/ MSER

F

```
 In this case the F statistic has  2 and  ```r n - 6 ``` degrees
 of freedom. We look to see how different this is from 1.0  or more formally compare to an F distribution with the two degrees of freedom. E.g.  at 95%
 
 ```{r}
 qf( .95, 2, n - 6)
 ```


# An alternative parameterization of the categorical variables
Create factors that are $\pm 1$  instead of 0 and 1. The OLS
parameters are different but the fit of the model is identical. 

```{r}
X2<- cbind(1, lungcap$Age, lungcap$Ht,
          2*(as.numeric( lungcap$Smoke)  - .5),
          2*(as.numeric( lungcap$Gender) - .5)
          )
         
X2<- cbind( X2, X[,4]* X[,5])

betaHat2<-  ( solve( t(X2)%*%X2) ) %*% t(X2)%*% log10(y)

c( betaHat2)

yHat<- X2%*%betaHat2
residuals<- log10(y) - yHat
sigma<-  sqrt( sum( residuals^2)/ ( n-p) )
sigma
# compare to lm
summary( lmObj3)$sigma
```

